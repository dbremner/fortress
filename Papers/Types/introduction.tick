A key feature of object-oriented languages is \emph{dynamic dispatch}: 
there may be multiple definitions of a function (or method) with the same name---%
we say the function is \emph{overloaded}---%
and a call to a function of that name is resolved
based on the ````run-time types''---we use the term \emph{ilks}---of the arguments, 
using the most specific definition 
that is applicable to arguments of their ilks.
With \emph{single dispatch}, 
a particular argument is designated as the \emph{receiver}, 
and the call is resolved only with respect to that argument.
With \emph{multiple dispatch}, 
the run-time types of  all arguments to a call are used to resolve the call.
\emph{Symmetric multiple dispatch} is a special case of multiple dispatch 
in which all arguments are considered equally when resolving a call.

Multiple dispatch provides great expressivity.
In particular, 
mathematical operators such as $+$ and $\leq$ and $\cup$
and especially $\cdot$ and $\times$
have different definitions depending on the types of the arguments
to an application of the operator
(even the number of arguments may vary between calls); 
in a language with multiple dispatch, 
it is natural to define these operators as overloaded functions. 
Similarly, 
many binary operations on collections such as `append` and `zip` 
have different definitions 
depending on the types of both arguments. 
\TODO{Add (reference to) argument for symmetric multiple dispatch?}

% \TODO{Alternative is to have a shorter intro, 
% which mostly mimics the abstract, but with a bit more elaboration,
% and I would probably leave the discussion of our prior work till later.
% We may want to mention Fortress early as a context for this work.
% Then have a long ````background'' section 
% containing the discussion starting from Castagna to Bourdoncle and Merz,
% and including the discussion of our prior work and former thoughts.}

% To preserve type safety 
% while incorporating multiple dispatch 
% into an object-oriented language with a static semantics, 
% the sets of valid overloaded definitions must be restricted.
% For example, to avoid ambiguous function calls,
% we must ensure that for every call site 
% (knowing only the static types of the arguments),
% there exists a unique ````best'' function to dispatch to at run time.\footnote{
% In languages with static overloading, 
% such as Scala, C\#, and the Java\texttrademark\ programming language 
% \cite{scala,CSharpSpec,JavaSpec}, 
% it is possible to simply reject ambiguous call sites of overloaded functions.
% However, as Millstein and Chambers have observed, 
% it is impossible to statically forbid ambiguity 
% in the presence of multiple dynamic dispatch 
% without imposing constraints at the definition sites of overloaded functions
% \cite{millstein02,millstein03}.
% \TODO{Is this true for asymmetric multiple dispatch?}}

\TODO{Removing footnote eliminated C\# reference.
Do we need to restore it?}

In an object-oriented language with symmetric multiple dispatch,
some restrictions must be placed on overloaded function definitions
to guarantee type safety.
% and avoid ambiguous function calls.
% \cite{castagna95,millstein02,millstein03}.
For example, 
consider the following overloaded function definitions:
\small
`  f(b:B, a:A): ZZ = 1
  f(a:A, b:B): ZZ = 2`
\normalsize
If $A$ is a subtype of $B$ (we write this as `A <: B`),
to which of these definitions do we dispatch 
when $f$ is called with two arguments of type $A$? 
% Note that the ambiguity is inherent in these definitions:
% there is a real question as to what behavior the programmer intended
% in this case.  

\TODO{Perhaps discussion of Castagna should move to related work.}

Castagna \textit{et al.} \cite{castagna95} address this problem 
in the context of a type system 
without parametric polymorphism or multiple inheritance
by requiring every pair of overloaded function definitions 
to satisfy the following properties:
(\emph{i}) whenever the domain type of one 
is a subtype of the domain type of the other, 
the return type of the first
must also be a subtype of the return type of the second; 
and 
(\emph{ii}) whenever the domain types of the two definitions 
have a common lower bound (i.e., a common nontrivial subtype), 
there is a unique definition for the same function 
whose domain type is the greatest lower bound 
of the domain types of the two definitions.
Thus, for the example above, 
% the solution of Castagna {\it et~al}.\ is to require the programmer to
the programmer must provide a third definition
to satisfy the latter property:
\small
`
  f(a:A,a':A): ZZ = ...
`\normalsize

We call this latter property the \emph{meet rule} 
because it is equivalent to requiring
that the definitions for each overloaded function form a meet semilattice 
partially ordered by the subtype relation on their domain types, 
which we call the \emph{more specific than} relation.\!\footnote{%
Despite its name,
this relation, like the subtype relation, is reflexive: 
two function definitions with the same domain type 
are each more specific than the other.
In that case, we say the definitions are equally specific.}
The meet rule guarantees 
that there are no ambiguous function calls at run time.

We call the first property above the \emph{return type rule} or \emph{subtype rule}.
It is needed to ensure type preservation 
% when the most specific function definition dynamically applicable to the arguments 
% (i.e., based on their ilks) 
% is more specific than the most specific definition statically applicable
% (i.e., based on the types of the expressions).
when a function call is resolved at run time 
(based on the ilks of the argument values) 
to a different (necessarily more specific) definition 
than the most specific one that could be determined at compile time 
(based on the types of the argument expressions).

In this paper, 
we give new meet and return type rules 
that ensure safe overloaded functions 
in a language that supports symmetric multiple dispatch, 
multiple inheritance, 
and parametric polymorphism for both types and functions
(i.e., generic types and generic functions), 
as the Fortress language we are developing does \cite{Fortress}.
We prove that these rules guarantee type safety.
% (see Section~\ref{sec:safety}).
This extends previous work \cite{allen07} 
in which we gave analogous rules, 
and proved the analogous result,
for a core of Fortress that does not support generics.

\TODO{Move next several paragaphs into a background section?}

To handle parametric polymorphism,
it is helpful to have an interpretation for generic types and functions.
One way to think about a generic type such as `List[\T\]`
(a list with elements of type `T`---type parameter lists 
in Fortress are delimited by white square brackets) 
is that it represents an infinite set of ground types 
`List[\Object\]` (lists of objects),
`List[\String\]` (lists of strings), 
`List[\ZZ\]` (lists of integers), 
and so on.
An actual type checker must have rules 
for working with uninstantiated (non-ground) generic types, 
but for many purposes this model of ````an infinite set of ground types'' 
is adequate for explanatory purposes.
Not so, however, for generic functions.  

One challenge in defining dynamic dispatch 
in the presence of overloaded generic functions 
is that the overloaded definitions
might have not only distinct argument types, 
but also distinct type parameters 
(even different numbers of type parameters), 
so the type values of these parameters 
make sense only in distinct type environments. 
For example, 
consider the following overloaded function definitions:
\small
`  combine[\T\](xs: List[\T\], ys: List[\T\]): List[\T\]
  combine[\S,T\](s: Table[\S,T\], t: Table[\S,T\]): Table[\S,T\]`
\normalsize
The first definition has a single type parameter `T`
(declared in the first pair of white square brackets)
denoting the types of the elements of the two list arguments $xs$ and $ys$
(occurences of `T` in the other pairs of white square brackets 
indicate that `T` is the type argument to the generic type `List`). 
The second definition has two type parameters 
corresponding to the domains and ranges of the two table arguments $s$ and $t$.
But the type parameter of the first definition 
bears no relation to the type parameters of the second.
How should we compare such function definitions 
to determine which is the best to dispatch to?
How can we ensure that there even is a best one in all cases?
Furthermore, the rules must be compatible with type inference, 
since instantiation of type parameters at a call site 
is typically done automatically.
So even determining which definitions are applicable 
to a particular call is not always obvious.


For some time during the development of Fortress, 
one of us (Steele) pushed for 
% we considered 
an interpretation of generic functions
analogous to the one above for generic types;
that is, 
that the generic function definition
% \footnote{%
% The first pair of white square brackets in each definition 
% delimits the type parameter declarations, 
% but the other pairs of white brackets 
% provide the type arguments to the generic types `List` and `Table`.}
\small
`  append[\T\](x: List[\T\], y: List[\T\]): List[\T\] = e
`
\normalsize
should be understood as if it stood for an infinite set of monomorphic definitions:
\small
`  append(x: List[\Object\], y: List[\Object\]): List[\Object\] = e
  append(x: List[\String\], y: List[\String\]): List[\String\] = e
  append(x: List[\ZZ\], y: List[\ZZ\]): List[\ZZ\] = e
  ...`
\normalsize
The intuition was that for any specific function call,
the usual rule for dispatch would then choose 
the appropriate most specific definition 
for this (infinitely) overloaded function.

Although that intuition worked well enough 
for a single polymorphic function definition,
it failed utterly when we considered multiple function definitions.
For example, 
a programmer might want to provide definitions 
for specific monomorphic special cases, as in:
\small
`  append[\T\](x: List[\T\], y: List[\T\]): List[\T\] = e1
  append(x: List[\ZZ\], y: List[\ZZ\]): List[\ZZ\] = e2`
\normalsize
If the interpretation above is taken seriously, 
this would be equivalent to:
\small
`  append(x: List[\Object\], y: List[\Object\]): List[\Object\] = e1
  append(x: List[\String\], y: List[\String\]): List[\String\] = e1
  append(x: List[\ZZ\], y: List[\ZZ\]): List[\ZZ\] = e1
  ...
  append(x: List[\ZZ\], y: List[\ZZ\]): List[\ZZ\] = e2`
\normalsize
and we can see that there is an ambiguity 
when the arguments are of type `List[\ZZ\]`.

It gets worse if the programmer wishes to handle an infinite set of cases specially.  
It would seem natural to write
\small
`  append[\T\](x: List[\T\], y: List[\T\]): List[\T\] = e1
  append[\T <: Number\](x: List[\T\], y: List[\T\]): List[\T\] = e2`
\normalsize
to handle specially all cases where `T` is a subtype of `Number`.
But the model would regard this as an overloaded function
with an infinite number of ambiguities.

Two authors of this paper (Hilburn and Kilpatrick) 
proposed to avoid these ambiguities 
by adopting an alternate model for generic functions 
similar to one proposed by Bourdoncle and Merz~\cite{bourdoncle97},
in which each function definition 
is regarded as a single definition whose domain type is an existential type, 
rather than as an infinite set of definitions
(a monomorphic definition is regarded as a degenerate generic one).
In this model, 
overloaded function definitions are (partially) ordered 
by the subtype relation on existential types, 
and dispatch and the meet rule 
can be adapted straightforwardly to use this new order.
The return type rule is somewhat more complicated 
but checking it similarly reduces to checking subtyping relationships 
between universal types.
Adopting this model has made overloaded generic functions in Fortress
both tractable and effective.

An important desideratum for our overloading rules 
is that they support modularity and extensibility.
In particular, 


We require extensibility.
Within that constraint, we want to be as permissive as possible.


Because the type hierarchy defined by a module may be extended,
and because Fortress supports multiple inheritance,
two types may have a common nontrivial subtype 
even if no declared type extends them both.
Thus,
for any pair of overloaded function definitions with incomparable domain types
(i.e., neither definition is more specific than the other),
the meet rule requires some other definition to resolve the potential ambiguity.
Because explicit intersection types cannot be expressed in Fortress, 
it is not always possible to provide such a function definition.
However, 
Fortress defines an \emph{exclusion relation} on types, 
such that types related by exclusion must have no common nontrivial subtypes,
and thus definitions with such types as domain types 
need not be disambiguated.


In providing rules to ensure 
that any valid set of overloaded function definitions 
guarantees that there is always a unique function to call at run time, 
we strive to be maximally permissive: 
A set of overloaded definitions should be disallowed 
only if it permits ambiguity
that cannot be resolved at run time.  
Nonetheless, 
we show in Section~\ref{sec:problems} 
that some seemingly valid sets of overloaded functions are rejected by our rules, 
and rightly so: 
although intuitively appealing, 
these overloaded functions admit ambiguous calls.

Many of these overloaded functions can, 
and we believe should, 
be allowed 
if the type system supports an \emph{exclusion relation},
which asserts that two types have no common instances.
If the domains of two function definitions exclude each other, 
then these definitions can never be applicable to the same call,
and so no ambiguity can arise between them.
Many languages provide a way of declaring some exclusion relations
implicitly. For example, single inheritance ensures that, for any 
two types, if one is not a subtype of the other, then the two types exclude each other.
Fortress enables programmers to declare ````nominal exclusion''
in addition to determining many exclusions implicitly, 
and in Section~\ref{sec:exclusion}, 
we formalize how Fortress does this, 
and show how this exclusion relation is used 
to improve expressivity 
by accommodating overloadings that would otherwise be rejected.
The proof of safety in Section~\ref{sec:safety} 
covers the rules under this extended type system.

To minimize syntactic overhead 
and avoid having to translate 
between a concrete language syntax 
and a formal semantics, 
we present these rules (see Section~\ref{sec:rules}) 
in the context of a straightforward formalization 
of a type system supporting multiple inheritance 
and parametric polymorphism, 
which we define in Section~\ref{sec:pre}.


% The remainder of this paper is organized thus:
% In Section~\ref{sec:pre}, we define the concepts and notation necessary
% to explain our formal rules for checking overloaded function definitions,
% which we present using universal and existential types in Section~\ref{sec:rules}.
% In Section~\ref{sec:problems}, 
% we explain why some apparently valid overloadings
% are (correctly) rejected by our rules 
% and why a multiple-inheritance language
% should include features for ````nominal exclusion'' (as Fortress does)
% to improve expressiveness and accommodate such overloadings.
% In Section~\ref{sec:exclusion}, we formalize the exclusion
% relation and use it to extend the overloading rules of Section~\ref{sec:rules}.
% %use it to augment the subtyping relation for universal and existential types.
% Section~\ref{sec:safety} explains that the overloading rules are
% sufficient to guarantee no undefined or ambiguous calls at run time.
% In Section~\ref{sec:discussion}, we discuss type inference and modularity.
% We discuss related work in Section~\ref{sec:related} and
% conclude in Section~\ref{sec:conclusion}.

