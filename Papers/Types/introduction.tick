A key feature of object-oriented languages is \emph{dynamic dispatch}: 
There may be multiple definitions of a function (or method) with the same name, 
and calls to a function (method) of that name are resolved
based on the ````run-time types''---we use the term \emph{ilks}---of the arguments. 
In \emph{single dispatch}, 
a particular argument is designated as the \emph{receiver}, 
and the call is resolved only with respect to that argument.
In \emph{multiple dispatch}, 
the run-time types of  all arguments to a call are used to resolve the call.
A special case of multiple dispatch is \emph{symmetric multiple dispatch}, 
in which all arguments are considered equally when resolving a call.

Multiple dynamic dispatch provides programmers with great expressivity.
In particular, 
mathematical operators such as $+$ and $\leq$ and $\cup$
and especially $\cdot$ and $\times$
have different definitions depending on the types of the arguments
to an application of the operator
(even the number of arguments may vary between calls); 
in a language with multiple dispatch, 
it is natural to define these operators as overloaded functions. 
Similarly, 
many binary operations on collections such as `append` and `zip` 
have different definitions 
depending on the types of both arguments. 

To preserve type soundness 
while incorporating multiple dispatch 
into an object-oriented language with a static semantics, 
constraints must be placed on the sets of valid overloaded definitions.
For example, to avoid ambiguous function calls,
we must ensure that for every call site 
(knowing only the static types of the arguments),
there exists a unique ````best'' function to dispatch to at run time.\footnote{
In languages with static overloading, such as Scala, C\#, and the Java\texttrademark\
programming language \cite{scala,CSharpSpec,JavaSpec}, it is possible to simply reject ambiguous call sites
of overloaded functions. However, as Millstein and Chambers have observed, 
it is impossible to statically forbid ambiguity in the presence of multiple dynamic
dispatch without imposing constraints at the definition sites of overloaded functions
\cite{millstein02,millstein03}.}

Castagna {\it et al}. showed how to check overloaded function definitions to
ensure this property in a language without parametric polymorphism~\cite{castagna92}.
In particular, the static type system must
impose a partial order on each set of overloaded definitions.  
This partial order may be described as: $m_1$ is more
specific than $m_2$ if and only if for every possible set of arguments,
if $m_1$ is applicable then $m_2$ is also applicable.
Every program is required to ensure that, 
for any two overloaded function definitions,
if neither is more specific than the other, 
then there is a third overloaded definition
that is (1) more specific than both and 
(2) no more specific than any other definable
function that is more specific than both. We can think of this property 
as imposing a
\emph{meet semi-lattice} on a set of function declarations.
Ensuring this property is complicated
because each of two function definitions 
might be more specific in one argument and not another. 
For example, 
consider the following overloaded function definitions:
\small
`  f(b:B, a:A)
  f(a:A, b:B)`
\normalsize
 If $A$ is a subtype of $B$ (we write this as `A <: B`),
to which of these definitions do we dispatch 
when $f$ is called with two arguments of type $A$? 
Note that the ambiguity is inherent in these definitions:
there is a real question as to what behavior the programmer intended
in this case.  The solution of Castagna {\it et~al}.\ is to require the programmer
 to provide a third overloading:
 \small
 `
 f(a:A,a':A)
 `
 \normalsize

Resolving ambiguous function calls becomes even more important,
and more difficult, in the presence of parametric polymorphism,
where both types and functions can be parameterized by type variables.
One way to think about a parametric type such as `List[\T\]`
(a list with elements of type `T`) is
that it represents an infinite set of ground types `List[\Object\]` (lists of objects),
`List[\String\]` (lists of strings), `List[\ZZ\]` (lists of integers), and so on.
In an actual type checker, it is necessary to have rules
for working with uninstantiated (non-ground) parametric types, but for many purposes
this model of ````an infinite set of ground types'' is adequate for explanatory purposes.
Not so, however, for type-parametric functions.  For quite some time during the
development of the Fortress language, one of us (Steele) pushed for understanding
a parametrically polymorphic function definition such as:
\small
`  append[\T\](x: List[\T\], y: List[\T\]): List[\T\] = e
`
\normalsize
(where the first pair of white square brackets delimits the declaration of a type parameter `T`,
 but the other pairs of white brackets indicate that this type variable `T` is the static
 argument to the parametric type `List`)
 as if that polymorphic definition stood for an infinite set of monomorphic definitions:
\small
`  append(x: List[\Object\], y: List[\Object\]): List[\Object\] = e
  append(x: List[\String\], y: List[\String\]): List[\String\] = e
  append(x: List[\ZZ\], y: List[\ZZ\]): List[\ZZ\] = e
  ...`
\normalsize
The intuition was that for any specific function call,
the usual rule for multimethod
dispatch would then choose the appropriate most specific
definition for this (infinitely) overloaded function.

That intuition worked well enough for a single polymorphic function definition,
but failed utterly when we considered multiple function definitions.
It would seem natural for a programmer to want to provide definitions for specific
monomorphic special cases:
\small
`  append[\T\](x: List[\T\], y: List[\T\]): List[\T\] = e1
  append(x: List[\ZZ\], y: List[\ZZ\]): List[\ZZ\] = e2`
\normalsize
but if the model is taken seriously, this would be equivalent to:
\small
`  append(x: List[\Object\], y: List[\Object\]): List[\Object\] = e1
  append(x: List[\String\], y: List[\String\]): List[\String\] = e1
  append(x: List[\ZZ\], y: List[\ZZ\]): List[\ZZ\] = e1
  ...
  append(x: List[\ZZ\], y: List[\ZZ\]): List[\ZZ\] = e2`
\normalsize
and we can see that there is an ambiguity (two definitions with the same signature)
when the arguments are
both of type `List[\ZZ\]`.

It only gets worse if the programmer wishes to handle an infinite set
of cases specially.  It would seem natural to write:
\small
`  append[\T\](x: List[\T\], y: List[\T\]): List[\T\] = e1
  append[\T <: Number\](x: List[\T\], y: List[\T\]): List[\T\] = e2`
\normalsize
so as to handle specially all cases where `T` is a subtype of `Number`,
but the model would regard this as an overloading with an infinite
number of ambiguities.

To resolve this problem, we had to develop an alternate
model and an associated type system that could handle overloaded
parametrically polymorphic functions in a manner that would accord
with programmer intuition and support the plausible examples shown above.
Credit for championing key insights---regarding each polymorphic definition
as a single definition (rather than an infinite set of definitions)
competing in the overload set, and using universal and existential types
to describe them in the type system (an idea reported by
Bourdoncle and Merz~\cite{bourdoncle97})---and for working out many difficult details
belongs to two other authors of this paper (Hilburn and Kilpatrick).
Adopting this new approach has made
overloaded polymorphic functions both tractable and effective
for writing Fortress code.

In this paper, 
we give rules for ensuring safe overloaded functions 
in a language that supports symmetric multiple dispatch, 
multiple inheritance, and parametric polymorphism 
(that is, generic types \emph{and} generic functions),
and we prove that these rules guarantee 
that there are no ambiguous calls at run time 
(see Section~\ref{sec:safety}).
We do this by extending our earlier rules 
for a core of the Fortress programming language 
that did not support generics \cite{allen07,fortress},
for which we proved the analogous theorem.
To minimize syntactic overhead 
and avoid having to translate 
between a concrete language syntax 
and a formal semantics, 
we present these rules (see Section~\ref{sec:rules}) 
in the context of a straightforward formalization 
of a type system supporting multiple inheritance 
and parametric polymorphism, 
which we define in Section~\ref{sec:pre}.

The problem of dynamic dispatch 
in the presence of overloaded \emph{generic} functions 
is challenging 
because the overloaded definitions
might have not only distinct argument types, 
but also distinct type parameters 
(even different numbers of type parameters), 
so the type values of these parameters 
make sense only in distinct type environments. 
For example, consider the following overloaded function definitions in Fortress:
\small
`  combine[\T\](xs: List[\T\], ys: List[\T\]): List[\T\]
  combine[\S,T\](s: Table[\S,T\], t: Table[\S,T\]): Table[\S,T\]`
\normalsize
The first definition declares a single
type parameter denoting the types of the elements of the two
list arguments $xs$ and $ys$. The second definition declares two 
type parameters corresponding to the domains and ranges of the two
table arguments $s$ and $t$. But the type parameter of the first
definition bears no relation to the type parameters of the second.
How should we compare such function definitions 
to determine which is the best to dispatch to?
How can we ensure that there even is a best one in all cases?
Furthermore, the rules must be compatible with type inference, 
since instantiation of type parameters at a call site 
is typically done automatically.
So even determining which definitions are applicable 
to a particular call is not always obvious.

In providing rules to ensure 
that any valid set of overloaded function definitions 
guarantees that there is always a unique function to call at run time, 
we strive to be maximally permissive: 
A set of overloaded definitions should be disallowed 
only if it permits ambiguity
that cannot be resolved at run time.  
Nonetheless, 
we show in Section~\ref{sec:problems} 
that some seemingly valid sets of overloaded functions are rejected by our rules, 
and rightly so: 
although intuitively appealing, 
these overloaded functions admit ambiguous calls.

Many of these overloaded functions can, 
and we believe should, 
be allowed 
if the type system supports an \emph{exclusion relation},
which asserts that two types have no common instances.
If the domains of two function definitions exclude each other, 
then these definitions can never be applicable to the same call,
and so no ambiguity can arise between them.
Many languages provide a way of declaring some exclusion relations
implicitly. For example, single inheritance ensures that, for any 
two types, if one is not a subtype of the other, then the two types exclude each other.
Fortress enables programmers to declare ````nominal exclusion''
in addition to determining many exclusions implicitly, 
and in Section~\ref{sec:exclusion}, 
we formalize how Fortress does this, 
and show how this exclusion relation is used 
to improve expressivity 
by accommodating overloadings that would otherwise be rejected.
The proof of safety in Section~\ref{sec:safety} 
covers the rules under this extended type system.

% The remainder of this paper is organized thus:
% In Section~\ref{sec:pre}, we define the concepts and notation necessary
% to explain our formal rules for checking overloaded function definitions,
% which we present using universal and existential types in Section~\ref{sec:rules}.
% In Section~\ref{sec:problems}, 
% we explain why some apparently valid overloadings
% are (correctly) rejected by our rules 
% and why a multiple-inheritance language
% should include features for ````nominal exclusion'' (as Fortress does)
% to improve expressiveness and accommodate such overloadings.
% In Section~\ref{sec:exclusion}, we formalize the exclusion
% relation and use it to extend the overloading rules of Section~\ref{sec:rules}.
% %use it to augment the subtyping relation for universal and existential types.
% Section~\ref{sec:safety} explains that the overloading rules are
% sufficient to guarantee no undefined or ambiguous calls at run time.
In Section~\ref{sec:discussion}, we discuss type inference and modularity.
We discuss related work in Section~\ref{sec:related} and
conclude in Section~\ref{sec:conclusion}.

